{
 "metadata": {
  "name": "temporal"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np;\n",
      "import networkx as nx\n",
      "import pickle\n",
      "import os, sys\n",
      "import scipy.linalg\n",
      "import matplotlib.pyplot as plt\n",
      "import igraph\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def nx_to_igraph(nxG):\n",
      "    a=nx.adjacency_matrix(nxG);\n",
      "    aa=list(np.array(a));\n",
      "    g=igraph.Graph.Weighted_Adjacency(aa);\n",
      "    return g;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def timevarying_graph_generator(data, edgelist,dim):\n",
      "    print data.shape, edgelist.shape\n",
      "    tempG={};\n",
      "    if dim!=0:\n",
      "        data=np.transpose(data);\n",
      "    print data.shape\n",
      "    T=data.shape[1];\n",
      "    print T\n",
      "    primal_graph=nx.read_edgelist(edgelist_file);\n",
      "    nodes=primal_graph.nodes()\n",
      "    relabel_dict={};\n",
      "    count=0;\n",
      "    for node in primal_graph.nodes():\n",
      "        relabel_dict[node]=count;\n",
      "        count+=1;\n",
      "    print 'Node relabeling complete.'\n",
      "    print 'Beginning construction of time-graph...'\n",
      "    for t in range(T):\n",
      "        if t%1000==0:\n",
      "            print 'tempo', t;\n",
      "        g=nx.Graph();\n",
      "        g.add_nodes_from(relabel_dict.values());\n",
      "        for i,state in enumerate(data[:,t]):\n",
      "            if state==1:\n",
      "                try:\n",
      "                    g.add_edge(relabel_dict[str(int(edgelist[i][0]))], relabel_dict[str(int(edgelist[i][1]))]);\n",
      "                except:\n",
      "                    print i,state;\n",
      "        tempG[t]=[];\n",
      "        tempG[t]=g;\n",
      "    return tempG;\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def calculate_transition_matrices(TG,N=None):\n",
      "    transition_matrix_dict={};\n",
      "    if N==None:\n",
      "        N=0;\n",
      "        for t in TG:\n",
      "            graph=TG[t];\n",
      "            if graph.number_of_nodes()>N:\n",
      "                N=graph.number_of_nodes();\n",
      "    \n",
      "    for t in TG:\n",
      "        graph=TG[t];\n",
      "        adj=nx.to_numpy_matrix(graph);\n",
      "        M=np.eye(N)+np.asarray(adj);\n",
      "        d=np.dot(M,np.ones((N,)));\n",
      "        for i,e in enumerate(d):\n",
      "            if e<=0:\n",
      "                print 'found zero row ', i, e, 'substituting it with 1';\n",
      "                d[i]=1;\n",
      "    \n",
      "        D=np.diag(d,0);\n",
      "\n",
      "        transition_matrix_dict[t]=[];\n",
      "        transition_matrix_dict[t]=np.dot(scipy.linalg.inv(D),M);\n",
      "    return transition_matrix_dict\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def activity_values(TG,m=1):\n",
      "    N=0;\n",
      "    for t in TG:\n",
      "        graph=TG[t];\n",
      "        if graph.number_of_nodes()>N:\n",
      "            N=graph.number_of_nodes();\n",
      "    \n",
      "    activity={};\n",
      "    z=[];\n",
      "    for t in TG:\n",
      "        graph=TG[t];\n",
      "        zz=0;\n",
      "        degree=graph.degree();\n",
      "        for n in degree:\n",
      "            if n in activity:\n",
      "                if degree[n]>0:\n",
      "                    activity[n]+=1;\n",
      "                    zz+=1;\n",
      "            else:\n",
      "                activity[n]=[];\n",
      "                if degree[n]>0:\n",
      "                    activity[n]=1;\n",
      "                    zz+=1;\n",
      "                else:\n",
      "                    activity[n]=0;\n",
      "        z.append(zz);\n",
      "        \n",
      "    norm_activity={};\n",
      "    eta = np.mean(z)/(np.mean(np.array(activity.values()))*N*m);\n",
      "    for key in activity:\n",
      "        norm_activity[key]=[];\n",
      "        norm_activity[key]=float(eta)*float(activity[key])/float(len(activity));\n",
      "    return norm_activity;  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "def stationary_weights_distributions(activity_dict,m,num_walkers,epsilon=0.1):\n",
      "    import sympy as sp;\n",
      "    av_activity=np.mean(activity_dict.values());\n",
      "    num_walkers=num_walkers/float(len(activity_dict)); \n",
      "    x=0;\n",
      "    num_iter=0;\n",
      "    step=0.0001;\n",
      "    phi_precision=100;\n",
      "    while (phi_precision>epsilon) and (num_iter<1000):\n",
      "        phi_precision=0;\n",
      "        for e in activity_dict:\n",
      "            phi_precision+=activity_dict[e]*(1/float(len(activity_dict))) * (m*num_walkers*activity_dict[e]+x)/(activity_dict[e]+m*av_activity);\n",
      "        phi_precision=np.abs(x-phi_precision);\n",
      "        print phi_precision\n",
      "        x+=step;\n",
      "        num_iter+=1;\n",
      "    print x, num_iter    \n",
      "    w = (np.array(activity_dict.values())*m*num_walkers+x)/ (np.array(activity_dict.values())+m*av_activity);\n",
      "    \n",
      "    return w/np.sum(w);\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def project_onto_community(TG, unproj_R, partition):\n",
      "    projected_R_tau={};\n",
      "    N=0;\n",
      "    for t in TG:\n",
      "        graph=TG[t];\n",
      "        if graph.number_of_nodes()>N:\n",
      "            N=graph.number_of_nodes();\n",
      "    num_comms=len(list(set(partition.values())));        \n",
      "    partition_index={};\n",
      "    for i,p in enumerate(list(set(partition.values()))):\n",
      "        partition_index[p]=i;\n",
      "    H=np.zeros((N,num_comms));\n",
      "    print H.shape;\n",
      "    for node in partition:\n",
      "        H[node][partition_index[partition[node]]]=1;\n",
      "    for key in unproj_R:\n",
      "        projected_R_tau[key]=[];\n",
      "        projected_R_tau[key] = np.trace(np.dot(np.transpose(H),np.dot(unproj_R[key],H))); \n",
      "    return projected_R_tau;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def aggregate_graph(TG):\n",
      "    new_graph=nx.Graph();\n",
      "    for t in TG:\n",
      "        graph=TG[t];\n",
      "        for node in graph.nodes():\n",
      "            if not new_graph.has_node(node):\n",
      "                new_graph.add_node(node);\n",
      "        for edge in graph.edges(data=True):\n",
      "            if new_graph.has_edge(edge[0],edge[1]):\n",
      "                new_graph[edge[0]][edge[1]]['weight']+=1;\n",
      "            else:\n",
      "                new_graph.add_edge(edge[0], edge[1], weight=1);\n",
      "\n",
      "    return new_graph;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def exponential_weighted_aggregated_temporal_graph(TG,omega=0.1):\n",
      "    edge_dict={};\n",
      "    for t in TG:\n",
      "        for edge in TG[t].edges():\n",
      "            if edge in edge_dict:\n",
      "                edge_dict[edge].append(t);\n",
      "            else:\n",
      "                edge_dict[edge]=[];\n",
      "                edge_dict[edge].append(t);\n",
      "    ExpG=nx.Graph();\n",
      "    for edge in edge_dict:\n",
      "        w=np.sum(np.exp(-float(omega)*np.diff(np.array(edge_dict[edge]))));\n",
      "        ExpG.add_edge(edge[0],edge[1],weight=w);\n",
      "    return ExpG;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def instant_partition_matrix(partition):\n",
      "    partition_index={};\n",
      "    for i,p in enumerate(list(set(partition.values()))):\n",
      "        partition_index[p]=i;\n",
      "    N=len(list(set(partition.keys())));\n",
      "    num_comms=len(list(set(partition.values())));        \n",
      "    H=np.zeros((N,num_comms));\n",
      "    print H.shape;\n",
      "    for node in partition:\n",
      "        H[node][partition_index[partition[node]]]=1;\n",
      "    return H; \n",
      "\n",
      "\n",
      "def temporal_projected_stationary_stability(TG,M_matrices, w, tau_values, temporal_partition, show_fig=False):\n",
      "    proj_R_tau={};\n",
      "    #define at which physical times the partition changes\n",
      "    partition_temporal_swaps = sorted(temporal_partition.keys());\n",
      "    #find number of nodes involved\n",
      "    N=0;\n",
      "    for t in TG:\n",
      "        graph=TG[t];\n",
      "        if graph.number_of_nodes()>N:\n",
      "            N=graph.number_of_nodes();\n",
      "\n",
      "    stationary_matrix=np.zeros((N,N));\n",
      "    for i,n in enumerate(w):\n",
      "        for j,l in enumerate(w):\n",
      "            stationary_matrix[i][j]=n*l;\n",
      "    \n",
      "    #start of loop on markov times \n",
      "    for tau in tau_values:\n",
      "        print tau\n",
      "        proj_R_tau[tau]=[];\n",
      "        counter=0;\n",
      "        tr_av=[];\n",
      "        keys=M_matrices.keys();\n",
      "        current_partition_time=0;\n",
      "        #start of loop on physical times\n",
      "        H=instant_partition_matrix(temporal_partition[partition_temporal_swaps[current_partition_time]]);\n",
      "        for t in range(len(M_matrices)-tau):\n",
      "            #check whether the partition is still the correct one for the physical time\n",
      "            if partition_temporal_swaps[(current_partition_time+1)%len(partition_temporal_swaps)]<=t and (current_partition_time+1)<len(partition_temporal_swaps):\n",
      "                current_partition_time+=1;\n",
      "                H=instant_partition_matrix(temporal_partition[partition_temporal_swaps[current_partition_time]]);\n",
      "            M_disposable=np.eye(N);\n",
      "            for i in range(tau):\n",
      "                M_disposable=np.dot(M_disposable,M_matrices[keys[t+i]]);\n",
      "            M_disposable=np.dot(np.diag(w,0),M_disposable) - stationary_matrix;\n",
      "            tr_av.append(np.trace(np.dot(H.T,np.dot(M_disposable,H))));\n",
      "        proj_R_tau[tau] = [];\n",
      "        proj_R_tau[tau] = np.mean(tr_av);\n",
      "    return proj_R_tau;\n",
      "\n",
      "\n",
      "def spinglass_partition(TG, t_min, t_max):\n",
      "    import igraph as ig;\n",
      "    import os;\n",
      "\n",
      "    TG_suppl={};\n",
      "    #select correct section of times\n",
      "    for t in TG:\n",
      "        if t>=t_min and t<t_max:\n",
      "            TG_suppl[t]=[];\n",
      "            TG_suppl[t]=TG[t];\n",
      "\n",
      "    new_graph=aggregate_graph(TG_suppl);\n",
      "    print new_graph.number_of_nodes();\n",
      "\n",
      "#    nx.write_pajek(new_graph,'temp_graph.net');\n",
      "#    g=ig.read('temp_graph.net',format=\"pajek\")\n",
      "#    os.remove('temp_graph.net');\n",
      "    Q=nx_to_igraph(new_graph).community_spinglass()\n",
      "    part_q={};\n",
      " #   print Q\n",
      "    for i,mem in enumerate(Q.membership):\n",
      "            part_q[i]=[];\n",
      "            part_q[i]=mem;\n",
      "    return part_q;\n",
      "\n",
      "def modularity_partition(TG, t_min, t_max):\n",
      "    import igraph as ig;\n",
      "    import os;\n",
      "\n",
      "    #select correct section of times\n",
      "    TG_suppl={};\n",
      "    for t in TG:\n",
      "        if t>=t_min and t<t_max:\n",
      "            TG_suppl[t]=[];\n",
      "            TG_suppl[t]=TG[t];\n",
      "\n",
      "    new_graph=aggregate_graph(TG_suppl);\n",
      "    print new_graph.number_of_nodes();\n",
      "   \n",
      "#    nx.write_pajek(new_graph,'temp_graph.net');\n",
      "#    g=ig.read('temp_graph.net',format=\"pajek\")\n",
      "#    os.remove('temp_graph.net');\n",
      "    Q=nx_to_igraph(new_graph).community_optimal_modularity()\n",
      "\n",
      "    part_q={};\n",
      "#    print Q\n",
      "    for i,mem in enumerate(Q.membership):\n",
      "            part_q[i]=[];\n",
      "            part_q[i]=mem;\n",
      "    return part_q;\n",
      "\n",
      "def infomap_partition(TG, t_min, t_max):\n",
      "    import igraph as ig;\n",
      "    import os;\n",
      "\n",
      "    #select correct section of times\n",
      "    TG_suppl={};\n",
      "    for t in TG:\n",
      "        if t>=t_min and t<t_max:\n",
      "            TG_suppl[t]=[];\n",
      "            TG_suppl[t]=TG[t];\n",
      "\n",
      "    new_graph=aggregate_graph(TG_suppl);\n",
      "    print new_graph.number_of_nodes();\n",
      "#    nx.write_pajek(new_graph,'temp_graph.net');\n",
      "#    g=ig.read('temp_graph.net',format=\"pajek\")\n",
      "#    os.remove('temp_graph.net');\n",
      "    Q=nx_to_igraph(new_graph).community_infomap()\n",
      "\n",
      "    part_q={};\n",
      "#    print Q\n",
      "    for i,mem in enumerate(Q.membership):\n",
      "            part_q[i]=[];\n",
      "            part_q[i]=mem;\n",
      "    print 'Number of clusters = ', len(list(set(part_q.values())));\n",
      "    return part_q;\n",
      "\n",
      "\n",
      "def fixed_delta_t_temporal_partition(TG, delta_t):\n",
      "    T_partition={};\n",
      "    for t in range(0,len(TG)-delta_t, delta_t):\n",
      "        T_partition[t]=[];\n",
      "        print 'Calculating infomap of slice ', t; \n",
      "        T_partition[t]=infomap_partition(TG,t,t+delta_t);\n",
      "    return T_partition;\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}